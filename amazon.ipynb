{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOJjxgze0DO7k/FLL1kA0WX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vibhorjoshi/kaggle-challenge/blob/main/amazon.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow opencv-python pillow numpy pandas\n"
      ],
      "metadata": {
        "id": "GQnd84iyG1cK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "from tqdm import tqdm\n",
        "from PIL import Image, UnidentifiedImageError\n",
        "from io import BytesIO\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "\n",
        "def is_valid_url(url):\n",
        "    \"\"\"Check if the URL is reachable.\"\"\"\n",
        "    try:\n",
        "        response = requests.head(url, allow_redirects=True)\n",
        "        return response.status_code == 200\n",
        "    except requests.RequestException:\n",
        "        return False\n",
        "\n",
        "def load_image(img_link, img_size=(224, 224)):\n",
        "    \"\"\"Load and preprocess an image from a URL or local file.\"\"\"\n",
        "    img_array = np.zeros((img_size[0], img_size[1], 3))  # Default to a blank image\n",
        "    try:\n",
        "        if img_link.startswith(('http://', 'https://')) and is_valid_url(img_link):\n",
        "            response = requests.get(img_link, stream=True)\n",
        "            response.raise_for_status()\n",
        "            img = Image.open(BytesIO(response.content))\n",
        "        else:\n",
        "            img = Image.open(img_link)\n",
        "\n",
        "        # Validate and process the image\n",
        "        if img.format in [\"JPEG\", \"PNG\"]:\n",
        "            img = img.convert('RGB')\n",
        "            img = img.resize(img_size)\n",
        "            img_array = img_to_array(img)\n",
        "            img_array = preprocess_input(img_array)\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported image format: {img.format}\")\n",
        "    except (requests.RequestException, UnidentifiedImageError, ValueError) as e:\n",
        "        print(f\"Error loading image {img_link}: {e}\")\n",
        "        # Use a blank or placeholder image for bad URLs or unsupported formats\n",
        "        img_array = np.zeros((img_size[0], img_size[1], 3))  # Blank image\n",
        "    except OSError as e:  # Handle truncated images\n",
        "        print(f\"Truncated image: {img_link}, error: {e}\")\n",
        "        img_array = np.zeros((img_size[0], img_size[1], 3))  # Use blank image\n",
        "\n",
        "    return img_array\n",
        "\n",
        "def load_images_pil(df, image_column, img_size=(224, 224), retry_count=3, top_n=1000):\n",
        "    \"\"\"Load and preprocess the top N images from a DataFrame column.\"\"\"\n",
        "    images = []\n",
        "    for i, img_link in enumerate(tqdm(df[image_column][:top_n], desc=f\"Downloading and processing top {top_n} images\")):\n",
        "        img_array = None\n",
        "        for attempt in range(retry_count):\n",
        "            img_array = load_image(img_link, img_size)\n",
        "            if np.any(img_array):  # Check if the image is non-empty\n",
        "                break\n",
        "            print(f\"Retrying {img_link}, attempt {attempt + 1}\")\n",
        "\n",
        "        images.append(img_array)\n",
        "\n",
        "    return np.array(images)\n",
        "\n",
        "# Example usage\n",
        "train_df = pd.read_csv('/content/train.csv')\n",
        "train_images = load_images_pil(train_df, 'image_link')\n",
        "print(\"Loaded train images shape:\", train_images.shape)\n",
        "\n",
        "# Extract the top 1000 images suited for the model\n",
        "top_1000_images = load_images_pil(train_df, 'image_link', top_n=1000)\n",
        "\n",
        "# Check shape of the loaded images\n",
        "print(\"Loaded top 1000 train images shape:\", top_1000_images.shape)\n",
        "\n"
      ],
      "metadata": {
        "id": "xV_DSlWnPNl-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Preprocess the entity_value (target) column (e.g., for weight)\n",
        "from sklearn.preprocessing import LabelEncoder # Import LabelEncoder from sklearn.preprocessing\n",
        "from sklearn.model_selection import train_test_split # Import train_test_split\n",
        "from tensorflow.keras.applications import VGG16 # Import VGG16\n",
        "from tensorflow.keras.layers import Flatten, Dense # Import Flatten and Dense layers\n",
        "from tensorflow.keras.models import Model # Import Model\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Ensure train_labels only includes labels for the top 1000 images\n",
        "train_labels = label_encoder.fit_transform(train_df['entity_value'][:1000])\n",
        "\n",
        "# Split the dataset for training and validation\n",
        "# Use top_1000_images which contains your 1000 image samples\n",
        "X_train, X_val, y_train, y_val = train_test_split(top_1000_images, train_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Train VGG16 Model\n",
        "def build_vgg16_model(input_shape):\n",
        "    # Load VGG16 without the top classification layer\n",
        "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "\n",
        "    # Freeze the base model layers (optional)\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    # Add custom layers on top\n",
        "    x = Flatten()(base_model.output)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    x = Dense(1, activation='linear')(x)  # Regression for predicting continuous entity values\n",
        "\n",
        "    model = Model(inputs=base_model.input, outputs=x)\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "    return model\n",
        "\n",
        "# Define input shape for VGG16 (224x224x3 for RGB images)\n",
        "input_shape = (224, 224, 3)\n",
        "\n",
        "# Build the model\n",
        "model = build_vgg16_model(input_shape)\n",
        "\n",
        "# Step 4: Train the model\n",
        "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, batch_size=32)\n",
        "\n",
        "# After training, we can test the model on the test.csv data"
      ],
      "metadata": {
        "id": "VgjgrVFhWaUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# step 5:\n",
        "# Load test images\n",
        "test_df = pd.read_csv('/content/sample_test.csv')\n",
        "test_images = load_images_pil(test_df, 'image_link')\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(test_images)\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "predicted_values = label_encoder.inverse_transform(predicted_labels)\n",
        "\n",
        "# Format predictions\n",
        "def format_predictions(predictions):\n",
        "    formatted_predictions = []\n",
        "    for pred in predictions:\n",
        "        # Assuming all predictions are in the format 'x unit' for simplicity\n",
        "        formatted_predictions.append(f\"{pred}\")\n",
        "    return formatted_predictions\n",
        "\n",
        "test_df['prediction'] = format_predictions(predicted_values)\n",
        "\n",
        "# Save predictions to CSV\n",
        "test_df[['index', 'prediction']].to_csv('D:\\acer\\Documents\\amazon ML Challenge\\student_resource 3\\dataset', index=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "pSFk18WEQWcD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# step-6\n",
        "import pandas as pd\n",
        "\n",
        "def evaluate_predictions(ground_truth_df, predictions_df):\n",
        "    \"\"\"Evaluate the predictions using F1 score calculation and generate CSV.\"\"\"\n",
        "    tp = fp = fn = 0\n",
        "\n",
        "    # Iterate over predictions and evaluate\n",
        "    for idx, pred in predictions_df.iterrows():\n",
        "        gt_row = ground_truth_df[ground_truth_df['index'] == pred['index']]\n",
        "\n",
        "        # If ground truth is missing for some reason, skip evaluation\n",
        "        if gt_row.empty:\n",
        "            continue\n",
        "\n",
        "        gt = gt_row['entity_value'].values[0]\n",
        "        out = pred['prediction']\n",
        "\n",
        "        # True Positive: Correct prediction and non-empty values\n",
        "        if out != \"\" and gt != \"\" and out == gt:\n",
        "            tp += 1\n",
        "        # False Positive: Prediction is made but incorrect or no ground truth\n",
        "        elif out != \"\" and (gt == \"\" or out != gt):\n",
        "            fp += 1\n",
        "        # False Negative: No prediction but there's a ground truth value\n",
        "        elif out == \"\" and gt != \"\":\n",
        "            fn += 1\n",
        "\n",
        "    # Precision, Recall, and F1 score calculations\n",
        "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    f1_score = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "    # Print evaluation results\n",
        "    print(f\"True Positives: {tp}, False Positives: {fp}, False Negatives: {fn}\")\n",
        "    print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1_score:.4f}\")\n",
        "\n",
        "    return f1_score\n",
        "\n"
      ],
      "metadata": {
        "id": "UwWouqUSSID4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "kvp79BbXk80r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the test data\n",
        "test_df = pd.read_csv('/content/sample_test.csv')\n",
        "\n",
        "# Load the test images using the same function\n",
        "test_images = load_images_pil(test_df, 'image_link')\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(test_images)\n",
        "\n",
        "# Convert predictions back to entity values (e.g., '34 gram')\n",
        "predicted_labels = label_encoder.inverse_transform(predictions.astype(int))\n",
        "\n",
        "# Create the output DataFrame\n",
        "output_df = pd.DataFrame({'index': test_df['index'], 'prediction': predicted_labels})\n",
        "\n",
        "# Save the output CSV\n",
        "output_df.to_csv('test_out.csv', index=False)\n",
        "\n",
        "# Verify the format using sanity.py (if necessary)\n"
      ],
      "metadata": {
        "id": "FM7-ZoMqkg7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_predictions_to_csv(predictions_df, output_file_path):\n",
        "    \"\"\"Save the predictions DataFrame to CSV in the required format.\"\"\"\n",
        "    predictions_df[['index', 'prediction']].to_csv(output_file_path, index=False)\n",
        "    print(f\"Predictions saved to {output_file_path}\")\n",
        "\n",
        "# Example Usage\n",
        "# Load the ground truth and predictions CSV files\n",
        "ground_truth_df = pd.read_csv('/content/sample_test_out.csv')  # Replace with actual ground truth\n",
        "predictions_df = pd.read_csv('/content/test.csv')  # Replace with actual predictions\n",
        "\n",
        "# Evaluate the predictions\n",
        "f1_score = evaluate_predictions(ground_truth_df, predictions_df)\n",
        "\n",
        "# Save predictions to CSV in the required format\n",
        "output_file_path = '/mnt/data/final_predictions.csv'\n",
        "save_predictions_to_csv(predictions_df, output_file_path)\n",
        "\n",
        "# Example usage for test predictions\n",
        "test_predictions = [\n",
        "    {\"index\": 1, \"prediction\": \"34 gram\"},\n",
        "    {\"index\": 2, \"prediction\": \"15 centimetre\"},\n",
        "    {\"index\": 3, \"prediction\": \"\"},\n",
        "    # Add other predictions here...\n",
        "]\n",
        "\n"
      ],
      "metadata": {
        "id": "Xj2lzggYYNsl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}